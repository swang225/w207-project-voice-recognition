{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c86a177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Loading Model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from jiwer import wer\n",
    "import pickle\n",
    "\n",
    "\n",
    "class LabelEncoder:\n",
    "\n",
    "    def __init__(self):\n",
    "        characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "        # encoder\n",
    "        self.char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "        # decoder\n",
    "        self.num_to_char = keras.layers.StringLookup(\n",
    "            vocabulary=self.char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    "        )\n",
    "\n",
    "    def encode(self, label):\n",
    "        label = tf.strings.lower(label)\n",
    "        label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "        return self.char_to_num(label)\n",
    "\n",
    "    def decode(self, nums):\n",
    "        return tf.strings.reduce_join(self.num_to_char(nums))\n",
    "\n",
    "\n",
    "def wav_to_audio(filepath):\n",
    "    file = tf.io.read_file(filepath)\n",
    "\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(\n",
    "        audio,\n",
    "        frame_length,\n",
    "        frame_step,\n",
    "        fft_length,\n",
    "):\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio,\n",
    "        frame_length=frame_length,\n",
    "        frame_step=frame_step,\n",
    "        fft_length=fft_length\n",
    "    )\n",
    "\n",
    "    # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "\n",
    "    # 6. normalisation\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def wav_to_features(\n",
    "        wav_file,\n",
    "        wavs_path,\n",
    "        frame_length,\n",
    "        frame_step,\n",
    "        fft_length,\n",
    "        add_suffix=True,\n",
    "):\n",
    "    file_path = wavs_path + wav_file\n",
    "    if add_suffix:\n",
    "        file_path += \".wav\"\n",
    "    audio = wav_to_audio(file_path)\n",
    "    spectrogram = audio_to_spectrogram(\n",
    "            audio=audio,\n",
    "            frame_length=frame_length,\n",
    "            frame_step=frame_step,\n",
    "            fft_length=fft_length,\n",
    "    )\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "class FeatureEncoder:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            wavs_path,\n",
    "            frame_length,\n",
    "            frame_step,\n",
    "            fft_length,\n",
    "            add_suffix,\n",
    "    ):\n",
    "        self.wavs_path = wavs_path\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.add_suffix = add_suffix\n",
    "\n",
    "    def features(\n",
    "            self,\n",
    "            wav_file,\n",
    "    ):\n",
    "        return wav_to_features(\n",
    "            wav_file=wav_file,\n",
    "            wavs_path=self.wavs_path,\n",
    "            frame_length=self.frame_length,\n",
    "            frame_step=self.frame_step,\n",
    "            fft_length=self.fft_length,\n",
    "            add_suffix=self.add_suffix\n",
    "        )\n",
    "\n",
    "\n",
    "class AudioContext:\n",
    "\n",
    "    _instance = None\n",
    "    _allowed = False\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            wavs_path,\n",
    "            frame_length,\n",
    "            frame_step,\n",
    "            fft_length,\n",
    "            add_suffix,\n",
    "    ):\n",
    "        if not AudioContext._allowed:\n",
    "            raise ValueError(\"Cannot instantiate AudioContext\")\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_encoder = FeatureEncoder(\n",
    "            wavs_path=wavs_path,\n",
    "            frame_length=frame_length,\n",
    "            frame_step=frame_step,\n",
    "            fft_length=fft_length,\n",
    "            add_suffix=add_suffix,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def set(\n",
    "            wavs_path,\n",
    "            frame_length,\n",
    "            frame_step,\n",
    "            fft_length,\n",
    "            add_suffix,\n",
    "    ):\n",
    "        AudioContext._allowed = True\n",
    "        AudioContext._instance = AudioContext(\n",
    "            wavs_path=wavs_path,\n",
    "            frame_length=frame_length,\n",
    "            frame_step=frame_step,\n",
    "            fft_length=fft_length,\n",
    "            add_suffix=add_suffix,\n",
    "        )\n",
    "        AudioContext._allowed = False\n",
    "\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        if AudioContext._instance is None:\n",
    "            raise ValueError(\"AudioContext not set yet\")\n",
    "\n",
    "        return AudioContext._instance\n",
    "\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "\n",
    "    lencoder = AudioContext.get().label_encoder\n",
    "    fencoder = AudioContext.get().feature_encoder\n",
    "\n",
    "    features = fencoder.features(wav_file)\n",
    "    encoded_label = lencoder.encode(label)\n",
    "\n",
    "    return features, encoded_label\n",
    "\n",
    "\n",
    "def create_dataset(data_df, batch_size):\n",
    "    _dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            list(data_df[\"file_name\"]),\n",
    "            list(data_df[\"normalized_transcription\"])\n",
    "        )\n",
    "    )\n",
    "    _dataset = (\n",
    "        _dataset.map(\n",
    "            encode_single_sample,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        .padded_batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "def CTCLoss(\n",
    "        y_true,\n",
    "        y_pred\n",
    "):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(\n",
    "        pred,\n",
    "        input_length=input_len,\n",
    "        greedy=True\n",
    "    )[0][0]\n",
    "\n",
    "    # Iterate over the results and get back the text\n",
    "    lencoder = AudioContext.get().label_encoder\n",
    "    res = []\n",
    "    for result in results:\n",
    "        result = lencoder.decode(result).numpy().decode(\"utf-8\")\n",
    "        res.append(result)\n",
    "    return res\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    def _acc(l, p):\n",
    "\n",
    "        l_len = len(l)\n",
    "        p_len = len(p)\n",
    "        count = 0\n",
    "        for i in range(min(l_len, p_len)):\n",
    "            if l[i] == p[i]:\n",
    "                count += 1\n",
    "\n",
    "        return count / max(l_len, p_len)\n",
    "\n",
    "    total_acc = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        total_acc += _acc(l, p)\n",
    "\n",
    "    avg_acc = total_acc / len(labels)\n",
    "    return avg_acc\n",
    "\n",
    "\n",
    "def abs_accuracy(labels, predictions):\n",
    "\n",
    "    def _acc(l, p):\n",
    "\n",
    "        if l == p:\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    total_acc = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        total_acc += _acc(l, p)\n",
    "\n",
    "    avg_acc = total_acc / len(labels)\n",
    "    return avg_acc\n",
    "\n",
    "\n",
    "class ModelEvaluator(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, dataset, model):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "\n",
    "    @staticmethod\n",
    "    def print(wer_score, res_acc, abs_acc, pred_df):\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Accuracy: {res_acc:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Abs accuracy: {abs_acc:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        print(pred_df.sample(n=5))\n",
    "\n",
    "    def do_prediction(self):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        lencoder = AudioContext.get().label_encoder\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = self.model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    lencoder.decode(label).numpy().decode(\"utf-8\") \\\n",
    "                    )\n",
    "                targets.append(label)\n",
    "\n",
    "        wer_score = wer(targets, predictions)\n",
    "        res_acc = accuracy(targets, predictions)\n",
    "        abs_acc = abs_accuracy(targets, predictions)\n",
    "        pred_df = pd.DataFrame(data={\"Label\": targets, \"predictions\": predictions})\n",
    "\n",
    "        return wer_score, res_acc, abs_acc, pred_df\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        wer_score, res_acc, abs_acc, pred_df = self.do_prediction()\n",
    "        self.history.append((wer_score, res_acc, abs_acc, pred_df))\n",
    "        self.print(wer_score, res_acc, abs_acc, pred_df)\n",
    "\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "    print(\"evaluate model against test dataset\")\n",
    "    test_evaluator = ModelEvaluator(\n",
    "        dataset=test_dataset,\n",
    "        model=model\n",
    "    )\n",
    "    wer_score, res_acc, abs_acc, pred_df = test_evaluator.do_prediction()\n",
    "    test_evaluator.print(wer_score, res_acc, abs_acc, pred_df)\n",
    "    return wer_score, res_acc, abs_acc, pred_df\n",
    "\n",
    "\n",
    "def write_pickle(data, file, ensure_exist=True):\n",
    "\n",
    "    if ensure_exist:\n",
    "        path = os.path.dirname(file)\n",
    "        if len(path) > 0:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    with open(file, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def read_pickle(file):\n",
    "    with open(file, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "def load_model(model_name, save_path):\n",
    "\n",
    "    model = keras.models.load_model(\n",
    "        os.path.join(save_path, model_name),\n",
    "        custom_objects={\"CTCLoss\": CTCLoss})\n",
    "    model_res = read_pickle(os.path.join(save_path, f\"{model_name}_validation.pkl\"))\n",
    "\n",
    "    return model, model_res\n",
    "\n",
    "\n",
    "# params\n",
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384\n",
    "\n",
    "AudioContext.set(\n",
    "    wavs_path=\"\",\n",
    "    frame_length=frame_length,\n",
    "    frame_step=frame_step,\n",
    "    fft_length=fft_length,\n",
    "    add_suffix=False\n",
    ")\n",
    "\n",
    "model_name = \"model005\"\n",
    "save_path = \"C:/data/models\"\n",
    "print(\"Loading Model\")\n",
    "model005, model_res = load_model(model_name, save_path)\n",
    "\n",
    "model_name = \"model005lj_half\"\n",
    "save_path = \"C:/data/models\"\n",
    "print(\"Loading Model\")\n",
    "model005lj, model_res = load_model(model_name, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf90da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "import queue\n",
    "import soundfile as sf\n",
    "import os\n",
    "from playsound import playsound\n",
    "import uuid\n",
    "\n",
    "\n",
    "class Recorder:\n",
    "    def __init__(self, model):\n",
    "        self.filepath = None\n",
    "        self.SAMPLE_RATE = 44100\n",
    "        self.CHANNELS = 1 # our decoder only handles 1 channel right now\n",
    "        self.sound_file = None\n",
    "        self.q = queue.Queue()\n",
    "        self.model = model\n",
    "\n",
    "    def record(self):\n",
    "        try:\n",
    "            self.filepath = f\"{uuid.uuid1()}_recording.wav\"\n",
    "            with sf.SoundFile(self.filepath,\n",
    "                              mode='x',\n",
    "                              samplerate=self.SAMPLE_RATE,\n",
    "                              channels=self.CHANNELS,\n",
    "                              subtype=None) as file:\n",
    "                self.sound_file = file\n",
    "\n",
    "                with sd.InputStream(samplerate=self.SAMPLE_RATE,\n",
    "                                    # device=self.mic_id,\n",
    "                                    channels=self.CHANNELS,\n",
    "                                    callback=self.callback):\n",
    "\n",
    "                    print(\"Recording started\")\n",
    "                    while True:\n",
    "                        file.write(self.q.get())\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            print(\"Recording stopped\")\n",
    "\n",
    "    def callback(self, indata, frames, time, status):\n",
    "        if status:\n",
    "            print(status, file=sys.stderr)\n",
    "        self.q.put(indata.copy())\n",
    "            \n",
    "    def stop(self):\n",
    "        try:\n",
    "            self.sound_file.flush()\n",
    "            self.sound_file.close()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def play(self):\n",
    "        print(\"Playing recording\")\n",
    "        if os.path.exists(self.filepath):\n",
    "            playsound(self.filepath)\n",
    "            print(\"Play recording complete\")\n",
    "        else:\n",
    "            print(\"No recording found\")\n",
    "            \n",
    "    def predict(self):\n",
    "        df = pd.DataFrame(data={\"file_name\": [self.filepath], \"normalized_transcription\": [\"a\"]})\n",
    "\n",
    "        test_dataset = create_dataset(data_df=df, batch_size=2)\n",
    "        test_evaluator = ModelEvaluator(dataset=test_dataset, model=self.model)\n",
    "        wer_score, res_acc, abs_acc, pred_df = test_evaluator.do_prediction()\n",
    "        res = pred_df.loc[0][\"predictions\"]\n",
    "        print(f\"Prediction: {res}\")\n",
    "        \n",
    "rec005 = Recorder(model=model005)\n",
    "rec005lj = Recorder(model=model005lj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ad13dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import GridspecLayout, Button, Layout, ButtonStyle\n",
    "import threading\n",
    "\n",
    "\n",
    "def click_record(btn):\n",
    "    t = threading.Thread(target=rec005.record)\n",
    "    t.start()\n",
    "    \n",
    "def click_stop(btn):\n",
    "    rec005.stop()\n",
    "    \n",
    "def click_play(btn):\n",
    "    rec005.play()\n",
    "    rec005.predict()\n",
    "\n",
    "def create_player005():\n",
    "    grid = GridspecLayout(1, 3)\n",
    "    grid[0, 0] = Button(\n",
    "        description=\"Play\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 0].on_click(click_play)\n",
    "    \n",
    "    grid[0, 1] = Button(\n",
    "        description=\"Stop\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 1].on_click(click_stop)\n",
    "    \n",
    "    grid[0, 2] = Button(\n",
    "        description=\"Record\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 2].on_click(click_record)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3400ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import GridspecLayout, Button, Layout, ButtonStyle\n",
    "import threading\n",
    "\n",
    "\n",
    "def click_record_lj(btn):\n",
    "    t = threading.Thread(target=rec005lj.record)\n",
    "    t.start()\n",
    "    \n",
    "def click_stop_lj(btn):\n",
    "    rec005lj.stop()\n",
    "    \n",
    "def click_play_lj(btn):\n",
    "    rec005lj.play()\n",
    "    rec005lj.predict()\n",
    "\n",
    "def create_player005lj():\n",
    "    grid = GridspecLayout(1, 3)\n",
    "    grid[0, 0] = Button(\n",
    "        description=\"Play\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 0].on_click(click_play_lj)\n",
    "    \n",
    "    grid[0, 1] = Button(\n",
    "        description=\"Stop\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 1].on_click(click_stop_lj)\n",
    "    \n",
    "    grid[0, 2] = Button(\n",
    "        description=\"Record\", \n",
    "        layout=Layout(height='auto', width='auto')\n",
    "    )\n",
    "    grid[0, 2].on_click(click_record_lj)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d58a4bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897d67db1ff940a8bef81d88ddbf2122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Button(description='Play', layout=Layout(grid_area='widget001', height='auto', width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started\n",
      "Recording stopped\n",
      "Playing recording\n",
      "Play recording complete\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "Prediction: alexa\n",
      "Recording started\n",
      "Recording stopped\n",
      "Playing recording\n",
      "Play recording complete\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "Prediction: alexa\n"
     ]
    }
   ],
   "source": [
    "player = create_player005()\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0aed491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f84a5e68134149bc74e197451f8efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Button(description='Play', layout=Layout(grid_area='widget001', height='auto', width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started\n",
      "Recording stopped\n",
      "Playing recording\n",
      "Play recording complete\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023487307790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "Prediction: f a\n",
      "Recording started\n",
      "Recording stopped\n",
      "Playing recording\n",
      "Play recording complete\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023487307790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Prediction: f ear\n",
      "Recording started\n",
      "Recording stopped\n",
      "Playing recording\n",
      "Play recording complete\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "Prediction: f  h\n"
     ]
    }
   ],
   "source": [
    "player_lj = create_player005lj()\n",
    "player_lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601537a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
